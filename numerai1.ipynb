{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00cf3078-a263-4831-899d-261043d67768",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'save_model' from 'utils' (C:\\Users\\farqu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumerapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumerAPI\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     save_model,\n\u001b[0;32m     12\u001b[0m     load_model,\n\u001b[0;32m     13\u001b[0m     neutralize,\n\u001b[0;32m     14\u001b[0m     get_biggest_change_features,\n\u001b[0;32m     15\u001b[0m     validation_metrics,\n\u001b[0;32m     16\u001b[0m     ERA_COL,\n\u001b[0;32m     17\u001b[0m     DATA_TYPE_COL,\n\u001b[0;32m     18\u001b[0m     TARGET_COL,\n\u001b[0;32m     19\u001b[0m     EXAMPLE_PREDS_COL\n\u001b[0;32m     20\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'save_model' from 'utils' (C:\\Users\\farqu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from numerapi import NumerAPI\n",
    "from utils import (\n",
    "    save_model,\n",
    "    load_model,\n",
    "    neutralize,\n",
    "    get_biggest_change_features,\n",
    "    validation_metrics,\n",
    "    ERA_COL,\n",
    "    DATA_TYPE_COL,\n",
    "    TARGET_COL,\n",
    "    EXAMPLE_PREDS_COL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0901c508-cd01-42e9-8590-7dae09f27dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 16:07:32,683 INFO numerapi.utils: target file already exists\n",
      "2023-04-24 16:07:32,683 INFO numerapi.utils: download complete\n",
      "2023-04-24 16:07:33,179 INFO numerapi.utils: target file already exists\n",
      "2023-04-24 16:07:33,179 INFO numerapi.utils: download complete\n",
      "2023-04-24 16:07:33,566 INFO numerapi.utils: target file already exists\n",
      "2023-04-24 16:07:33,566 INFO numerapi.utils: download complete\n",
      "2023-04-24 16:07:33,957 INFO numerapi.utils: target file already exists\n",
      "2023-04-24 16:07:33,972 INFO numerapi.utils: download complete\n",
      "2023-04-24 16:07:34,563 INFO numerapi.utils: target file already exists\n",
      "2023-04-24 16:07:34,563 INFO numerapi.utils: download complete\n",
      "2023-04-24 16:07:34,946 INFO numerapi.utils: target file already exists\n",
      "2023-04-24 16:07:34,946 INFO numerapi.utils: download complete\n",
      "2023-04-24 16:07:35,369 INFO numerapi.utils: target file already exists\n",
      "2023-04-24 16:07:35,369 INFO numerapi.utils: download complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'meta_model.parquet'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "napi = NumerAPI()\n",
    "napi.download_dataset(\"v4.1/train.parquet\", \"train.parquet\")\n",
    "napi.download_dataset(\"v4.1/validation.parquet\", \"validation.parquet\")\n",
    "napi.download_dataset(\"v4.1/live.parquet\", \"live.parquet\")\n",
    "napi.download_dataset(\"v4.1/live_example_preds.parquet\", \"live_example_preds.parquet\")\n",
    "napi.download_dataset(\"v4.1/validation_example_preds.parquet\", \"validation_example_preds.parquet\")\n",
    "napi.download_dataset(\"v4.1/features.json\", \"features.json\")\n",
    "napi.download_dataset(\"v4.1/meta_model.parquet\", \"meta_model.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63bddbf5-f998-495e-b79f-9bdfe6e721b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ERA_COL' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m     feature_metadata \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      7\u001b[0m features \u001b[38;5;241m=\u001b[39m feature_metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfeature_sets\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# get the medium feature set\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m read_columns \u001b[38;5;241m=\u001b[39m features \u001b[38;5;241m+\u001b[39m [\u001b[43mERA_COL\u001b[49m, DATA_TYPE_COL, TARGET_COL]\n\u001b[0;32m     11\u001b[0m training_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m                                 columns\u001b[38;5;241m=\u001b[39mread_columns)\n\u001b[0;32m     13\u001b[0m validation_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidation.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m                                   columns\u001b[38;5;241m=\u001b[39mread_columns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ERA_COL' is not defined"
     ]
    }
   ],
   "source": [
    "napi = NumerAPI()\n",
    "\n",
    "current_round = napi.get_current_round()\n",
    "\n",
    "with open(\"features.json\", \"r\") as f:\n",
    "    feature_metadata = json.load(f)\n",
    "features = feature_metadata[\"feature_sets\"][\"medium\"] # get the medium feature set\n",
    "\n",
    "read_columns = features + [ERA_COL, DATA_TYPE_COL, TARGET_COL]\n",
    "\n",
    "training_data = pd.read_parquet('train.parquet',\n",
    "                                columns=read_columns)\n",
    "validation_data = pd.read_parquet('validation.parquet',\n",
    "                                  columns=read_columns)\n",
    "live_data = pd.read_parquet(f'live_{current_round}.parquet',\n",
    "                                  columns=read_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
